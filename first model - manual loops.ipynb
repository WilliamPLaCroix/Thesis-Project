{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFOfr6gp0ha_",
        "outputId": "bc60ba28-56ed-42ed-fd9c-7c6296e590b7"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install pytorch_lightning\n",
        "# !pip install py-readability-metrics\n",
        "# !python -m nltk.downloader punkt\n",
        "# !pip install evaluate\n",
        "# !pip install sacremoses sacrebleu\n",
        "# !pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTLaR_HI0Tj7",
        "outputId": "c8de3703-b556-448b-fa8e-2f8985403fd9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import pickle\n",
        "from transformers import AutoConfig\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers.utils import PaddingStrategy\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from evaluate import load\n",
        "sari = load(\"sari\")\n",
        "\n",
        "\n",
        "data_location = './data/wikilarge/'\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_name = 'gpt2'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "config = AutoConfig.from_pretrained(model_name,\n",
        "    max_new_tokens=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IsN7Yx420Tj9"
      },
      "outputs": [],
      "source": [
        "class TrainingArguments:\n",
        "    def __init__(self):\n",
        "        self.output_dir = \"./output/\"\n",
        "        self.evaluation_strategy = \"epoch\"\n",
        "        self.batch_size = 8\n",
        "        self.adam_beta1 = 0.9\n",
        "        self.adam_beta2 = 0.999\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.lr_scheduler_type = \"linear\"\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.max_steps = -1\n",
        "        self.num_train_epochs = 3\n",
        "        self.seed = 42\n",
        "        self.warmup_steps = 0\n",
        "        self.weight_decay = 0.0\n",
        "        self.max_sequence_length = 126\n",
        "        # self.logging_dir = \"./logs\"\n",
        "        # self.logging_first_step = False\n",
        "        # self.logging_steps = 500\n",
        "        # self.save_steps = 500\n",
        "        # self.save_total_limit = 1\n",
        "\n",
        "    def __str__(self):\n",
        "        print(\"Training Arguments / Hyperparameters:\")\n",
        "        print(\"---------------------------------\")\n",
        "        for key, value in self.__dict__.items():\n",
        "            print(f\"| {key}: {value}\")\n",
        "        return \"--------------------------------\"\n",
        "training_args = TrainingArguments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "\n",
        "    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(training_args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmfdEVyYEk6h",
        "outputId": "7f656c31-6532-4dbc-fdc7-71d5de8d143d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Arguments / Hyperparameters:\n",
            "---------------------------------\n",
            "| output_dir: ./output/\n",
            "| evaluation_strategy: epoch\n",
            "| batch_size: 8\n",
            "| adam_beta1: 0.9\n",
            "| adam_beta2: 0.999\n",
            "| adam_epsilon: 1e-08\n",
            "| gradient_accumulation_steps: 1\n",
            "| learning_rate: 5e-05\n",
            "| lr_scheduler_type: linear\n",
            "| max_grad_norm: 1.0\n",
            "| max_steps: -1\n",
            "| num_train_epochs: 3\n",
            "| seed: 42\n",
            "| warmup_steps: 0\n",
            "| weight_decay: 0.0\n",
            "| max_sequence_length: 126\n",
            "--------------------------------\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "print(training_args)\n",
        "print(training_args.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6yjcLo_s0Tj9"
      },
      "outputs": [],
      "source": [
        "# grade_ratio = pd.read_csv(f'{data_location}grade_ratio_wiki_train.csv')\n",
        "# # source texts\n",
        "# with open(f'{data_location}wiki_train.src', 'r', encoding='utf-8') as f:\n",
        "#     train_src = f.readlines()\n",
        "# train_src = pd.DataFrame(train_src, columns=['source'])\n",
        "# # target texts\n",
        "# with open(f'{data_location}wiki_train.tgt', 'r', encoding='utf-8') as f:\n",
        "#     train_tgt = f.readlines()\n",
        "# train_tgt = pd.DataFrame(train_tgt, columns=['target'])\n",
        "# train_texts = pd.concat([train_src, grade_ratio['abs_src_FKGL_Grade'], train_tgt, grade_ratio['abs_tgt_FKGL_Grade']], axis=1)\n",
        "# train_texts.rename(columns={'abs_src_FKGL_Grade': 'source_grade', 'abs_tgt_FKGL_Grade': 'target_grade'}, inplace=True)\n",
        "# train_texts['souce'] = train_texts['source'].replace(r'\\n','', regex=True)\n",
        "# train_texts['target'] = train_texts['target'].replace(r'\\n','', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tgN8Zdr70Tj-",
        "outputId": "273b35a6-44d5-4740-80ec-e97390164bd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Heinrich Luitpold Himmler (7 October 1900 - 23 May 1945) was Chief of the German Police and Minister of the Interior.\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts = pd.read_pickle(f'{data_location}train_texts.pkl')\n",
        "train_texts.iloc[0]['source']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "ip5PeaXm0Tj-",
        "outputId": "fa9f1e9a-beb2-4ecc-fa55-580bf2c145bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_grade</th>\n",
              "      <th>target</th>\n",
              "      <th>target_grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Though founded in 1887, under Jack Hyles' lead...</td>\n",
              "      <td>13</td>\n",
              "      <td>Dr. Jack Hyles\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>On January 27, 2008, at the NHL All-Star Game ...</td>\n",
              "      <td>7</td>\n",
              "      <td>Records\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>Gone the times when nations battled for this' ...</td>\n",
              "      <td>8</td>\n",
              "      <td>gone the days when strife and discord.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>May 17 &amp; ndash; The conflict between Toyotomi ...</td>\n",
              "      <td>10</td>\n",
              "      <td>Ghent falls to the Spanish.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Some subjects that are discussed have criminal...</td>\n",
              "      <td>11</td>\n",
              "      <td>(see and).\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216813</th>\n",
              "      <td>Dubnium (,) is a chemical element with the sym...</td>\n",
              "      <td>10</td>\n",
              "      <td>It has the symbol Db.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216828</th>\n",
              "      <td>WWE Hell in a Cell is a professional wrestling...</td>\n",
              "      <td>13</td>\n",
              "      <td>Hell\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216833</th>\n",
              "      <td>He died of a heart attack in 1968 and was hono...</td>\n",
              "      <td>8</td>\n",
              "      <td>He died from a heart attack in 1968.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216839</th>\n",
              "      <td>In English, the name is sometimes spelled Bela...</td>\n",
              "      <td>10</td>\n",
              "      <td>-)\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216850</th>\n",
              "      <td>Such desks are sometimes called left-pedestal ...</td>\n",
              "      <td>5</td>\n",
              "      <td>Desks can be used at home.\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10990 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   source  source_grade  \\\n",
              "5       Though founded in 1887, under Jack Hyles' lead...            13   \n",
              "121     On January 27, 2008, at the NHL All-Star Game ...             7   \n",
              "130     Gone the times when nations battled for this' ...             8   \n",
              "152     May 17 & ndash; The conflict between Toyotomi ...            10   \n",
              "172     Some subjects that are discussed have criminal...            11   \n",
              "...                                                   ...           ...   \n",
              "216813  Dubnium (,) is a chemical element with the sym...            10   \n",
              "216828  WWE Hell in a Cell is a professional wrestling...            13   \n",
              "216833  He died of a heart attack in 1968 and was hono...             8   \n",
              "216839  In English, the name is sometimes spelled Bela...            10   \n",
              "216850  Such desks are sometimes called left-pedestal ...             5   \n",
              "\n",
              "                                          target  target_grade  \n",
              "5                               Dr. Jack Hyles\\n             0  \n",
              "121                                    Records\\n             0  \n",
              "130     gone the days when strife and discord.\\n             0  \n",
              "152                Ghent falls to the Spanish.\\n             0  \n",
              "172                                 (see and).\\n             0  \n",
              "...                                          ...           ...  \n",
              "216813                   It has the symbol Db.\\n             0  \n",
              "216828                                    Hell\\n             0  \n",
              "216833    He died from a heart attack in 1968.\\n             0  \n",
              "216839                                      -)\\n             0  \n",
              "216850              Desks can be used at home.\\n             0  \n",
              "\n",
              "[10990 rows x 4 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grade_groups = train_texts.groupby(['target_grade'])\n",
        "grade_groups.get_group(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP5sgaZk0Tj-",
        "outputId": "a85755ad-a0ba-4d9b-a541-26971e0e0ca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['source', 'target', 'target_grade', '__index_level_0__'],\n",
              "        num_rows: 20313\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['source', 'target', 'target_grade', '__index_level_0__'],\n",
              "        num_rows: 5079\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create custom dataset where each grade group is a separate dataset, including source, target, and target grade\n",
        "datasets = {}\n",
        "for i, (grade, group) in enumerate(grade_groups):\n",
        "    datasets[i] = Dataset.from_pandas(group[['source', 'target', 'target_grade']]).train_test_split(test_size=0.2)\n",
        "\n",
        "datasets[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXdpaiP90Tj-",
        "outputId": "75e0140c-1102-4879-93e1-b47b7b547ebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['source', 'target', 'target_grade', '__index_level_0__'],\n",
              "    num_rows: 20313\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets[6]['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259,
          "referenced_widgets": [
            "b4fc45c1a950454fbb3cafbfe4893681",
            "c78098600100460483ac0587a8c19c71",
            "2fef12b0bf154bcb96af91c2b7aeac9d",
            "1aca0d72fffa4bde8e8dd52af9cff9f9",
            "fc119722a901433a851416f9fbb6586c",
            "fe51e1dd6e8f43e6a1e5639552d64baa",
            "c0fa656ecfff42e7b4267cc27d711025",
            "c4b02b3f357b48958c5b5a9560230ba5",
            "b3ce635eb26e455799bba15b03bc2680",
            "d85ce6a9a3e04c40b7c01ea253cb489c",
            "c16270989c4a42bdaad5b8d798b67f44",
            "e88ca4ace1714f808dd316b0e201c70c",
            "4dc2f24808444c2e8fe361b805540536",
            "7cbc2f511cfa4d24823990f1f8f99285",
            "70b6190d0ac34cbab2e2d679edfb5e4c",
            "9946327fc8484a899eeade3d04b3ebf0",
            "08e2d36688ca4570a58f2cf6ecc31660",
            "40ad8ad5dbbc448d9ce9b88f3c950233",
            "7ffe83e3794e465bbaf0263add300d1e",
            "8b0cdf891dfe4f88994737144f2e9d6c",
            "b634c856a1d9485bab369cbb6e0e1a4b",
            "9aa23785abf74453af9f16289d74e485"
          ]
        },
        "id": "n8mRnmuM0Tj-",
        "outputId": "3baa86b0-1293-4176-86c0-7f1d7ec8b7f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52759064e44c4789b543dd366c840b95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20313 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b81f96a1f2a40c3a974100654a9ecea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5079 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# def pre_tokenize_function(examples):\n",
        "#     return tokenizer(text=examples[\"source\"], text_target=examples['target'], padding=True, max_length=training_args.max_sequence_length, return_tensors=\"pt\")\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(text=examples[\"source\"], text_target=examples['target'], padding=True, max_length=training_args.max_sequence_length, return_tensors=\"pt\")\n",
        "\n",
        "tokenized_dataset = datasets[6].map(tokenize_function, batched=True, batch_size=training_args.batch_size,\n",
        "                                      remove_columns=['source', 'target', '__index_level_0__'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2vgtTqNEk6j",
        "outputId": "1312816f-8f57-41b1-e371-21a0fb04391e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n",
            "35\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_dataset['train'][100]['input_ids']))\n",
        "print(len(tokenized_dataset['train'][100]['attention_mask']))\n",
        "print(len(tokenized_dataset['train'][100]['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmKmSqnAEk6j",
        "outputId": "cc443620-5142-4f05-ef7b-62bb22b5e29d"
      },
      "outputs": [],
      "source": [
        "def find_max_len(tokenized_dataset):\n",
        "    longest_source = 0\n",
        "    source = ''\n",
        "    longest_target = 0\n",
        "    target = ''\n",
        "    for dataset in ['train', 'test']:\n",
        "        for example in tokenized_dataset[dataset]:\n",
        "            source_len = len(example['input_ids'])\n",
        "            target_len = len(example['labels'])\n",
        "            if source_len > longest_source:\n",
        "                longest_source = source_len\n",
        "                source = example['input_ids']\n",
        "            if target_len > longest_target:\n",
        "                longest_target = target_len\n",
        "                target = example['labels']\n",
        "    return max(longest_source, longest_target)\n",
        "\n",
        "training_args.max_sequence_length = find_max_len(tokenized_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenized_dataset = datasets[6].map(tokenize_function, batched=True, batch_size=training_args.batch_size,\n",
        "#                                       remove_columns=['source', 'target', '__index_level_0__'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n",
            "35\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_dataset['train'][100]['input_ids']))\n",
        "print(len(tokenized_dataset['train'][100]['attention_mask']))\n",
        "print(len(tokenized_dataset['train'][100]['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "orJgXr3G0Tj_"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=\"max_length\", max_length=training_args.max_sequence_length, label_pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(tokenized_dataset['train'], batch_size=training_args.batch_size, shuffle=True, collate_fn=data_collator)\n",
        "eval_data_loader = torch.utils.data.DataLoader(tokenized_dataset['test'], batch_size=training_args.batch_size, shuffle=False, collate_fn=data_collator)\n",
        "dataloaders = {'train': train_data_loader, 'eval': eval_data_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFOKAqn_Ek6j",
        "outputId": "3e366ec4-ab5c-4512-c084-56fc08c17c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 98])\n",
            "torch.Size([8, 98])\n",
            "torch.Size([8, 98])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_data_loader:\n",
        "    print(batch['input_ids'].shape)\n",
        "    print(batch['attention_mask'].shape)\n",
        "    print(batch['labels'].shape)\n",
        "    print(batch['target_grade'].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Ya_6ba5R0Tj_"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(prediction):\n",
        "    source_ids, pred_ids, labels_ids = prediction\n",
        "    sources = []\n",
        "    labels = []\n",
        "    predictions = []\n",
        "\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "    source_str = tokenizer.batch_decode(source_ids, skip_special_tokens=True)\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "    sources.append(''.join(source_str))\n",
        "    labels.append([''.join(label_str)])\n",
        "    predictions.append(''.join(pred_str))\n",
        "\n",
        "\n",
        "    return sari.compute(sources=sources, predictions=predictions, references=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLrcLapGEk6k",
        "outputId": "63120e08-b0f3-4790-9b80-3c724e75d3d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sari': 97.43589743589745}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_metrics([tokenized_dataset['train'][1]['input_ids'], tokenized_dataset['train'][1]['labels'], tokenized_dataset['train'][1]['labels']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0YQvsqezEk6k"
      },
      "outputs": [],
      "source": [
        "class FineTuneGPT2(nn.Module):\n",
        "    def __init__(self, model, tokenizer, training_args):\n",
        "        super(FineTuneGPT2, self).__init__()\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        self.training_args = training_args\n",
        "        # self.save_hyperparameters()\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.configure_optimizers()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # print(\"input shape:\", input_ids.shape)\n",
        "        # print(\"attn shape:\", attention_mask.shape)\n",
        "        # print(\"labels shape:\", labels.shape)\n",
        "        print(\"forward\")\n",
        "        return self.model(input_ids, attention_mask=attention_mask, labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aT4m2zyPEk6k"
      },
      "outputs": [],
      "source": [
        "def train_test(model, dataloader, optimizer, training):\n",
        "    \"\"\"\n",
        "    Performs a single epoch of training, validation, or testing on the given model using the specified DataLoader.\n",
        "    This function adapts its behavior based on the 'training' parameter to correctly handle the model's state and\n",
        "    perform necessary operations such as backpropagation and optimizer updates during training.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): The neural network model to be trained, validated, or tested.\n",
        "        dataloader (DataLoader): A DataLoader providing batches of data (features and labels) for processing.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer (AdamW) to use for updating model parameters during training.\n",
        "        pos_weight (torch.Tensor): A tensor specifying the weight for the positive class to handle class imbalance.\n",
        "        training (str): A string specifying the mode of operation. Must be 'train', 'validation', or 'test'.\n",
        "\n",
        "    Returns:\n",
        "        None if training.\n",
        "        Cumulative loss (float) if validation.\n",
        "        A tuple (label_list, prediction_list) containing lists of true labels and predicted labels for\n",
        "        each sample if testing.\n",
        "    \"\"\"\n",
        "    # BCEWithLogitsLoss combines sigmoid with BCELoss for better stability, and handles class imbalance via pos_weight\n",
        "\n",
        "    if training == \"train\":\n",
        "        model.train()\n",
        "    elif training == \"validation\":\n",
        "        model.eval()\n",
        "    elif training == \"test\":\n",
        "        model.eval()\n",
        "    else:\n",
        "        raise ValueError(\"training argument must be either 'train', 'validation' or 'test'\")\n",
        "\n",
        "    cumulative_loss = 0\n",
        "    input_list = [] # store inputs accross folds for calculating metrics\n",
        "    prediction_list = [] # store predictions accross folds for calculating accuracy and f1\n",
        "    label_list = [] # store labels accross folds for calculating accuracy and f1\n",
        "\n",
        "    for sample in tqdm(dataloader): # iterate over batches in the DataLoader\n",
        "        sample.to(device)\n",
        "        input, attention_mask, labels = sample[\"input_ids\"], sample[\"attention_mask\"], sample['labels']\n",
        "        output = model(input, attention_mask, labels) # forward pass\n",
        "        loss_value = output.loss\n",
        "        cumulative_loss += loss_value.item()\n",
        "\n",
        "        if training == \"train\":\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "        labels_temp = []\n",
        "        labels_temp.append(labels.to('cpu').detach().numpy())\n",
        "        input_list.extend(input.to('cpu').detach().numpy())\n",
        "        prediction_list.extend(torch.argmax(output.logits, dim=-1).to('cpu').detach().numpy())\n",
        "        label_list.extend(labels_temp)\n",
        "\n",
        "\n",
        "    if training == \"train\":\n",
        "        print(\"mean training loss:\", cumulative_loss)\n",
        "        print(compute_metrics((input, torch.argmax(output.logits, dim=-1), labels)))\n",
        "        return cumulative_loss\n",
        "    elif training == \"validation\":\n",
        "        print(\"mean validation loss:\", cumulative_loss)\n",
        "        return cumulative_loss\n",
        "    elif training == \"test\":\n",
        "        return label_list, prediction_list\n",
        "    else:\n",
        "        raise ValueError(\"Ya Done Fuck'd up, son!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rwl8B1vyEk6l"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloaders, training_args):\n",
        "    \"\"\"\n",
        "    Evaluates neural model's performance on a given task using specified parameters.\n",
        "    The function preprocesses the data, splits it according to the task, initializes a TuneableModel,\n",
        "    and trains it. It then evaluates the model on a test set and returns performance metrics.\n",
        "\n",
        "    The function asserts the task to be one of the predefined tasks and initializes the model based on\n",
        "    the provided parameters. It supports dynamic pos_weight handling and uses early stopping based on\n",
        "    validation loss to prevent overfitting.\n",
        "\n",
        "    Parameters:\n",
        "        data (pd.DataFrame): The dataset to evaluate the model on.\n",
        "        parameters (dict): A dictionary containing model hyperparameters and training settings. Expected\n",
        "            keys include \"pos_weight\", \"batch_size\", \"alpha\", \"hidden_size\", \"dropout\", \"n_hidden\",\n",
        "            \"learning_rate\", \"beta_1\", and \"beta_2\".\n",
        "        task (int): An integer indicating the task type. Valid values are 0, 1, 2, and 3, each representing\n",
        "            a different way of splitting the data for training and testing:\n",
        "                0 - Known subjects and items with k-fold cross-validation.\n",
        "                1 - Known subjects and items with leave-one-out cross-validation.\n",
        "                2 - Held-out subjects, known items.\n",
        "                3 - Held-out items, known subjects.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the accuracy score, F1 score, and confusion matrix of the model evaluated\n",
        "            on a given test set.\n",
        "    \"\"\"\n",
        "\n",
        "    max_epochs = 1000\n",
        "\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    gpt_new = FineTuneGPT2(model, tokenizer, training_args)\n",
        "    gpt_new.to(device)\n",
        "    optimizer = torch.optim.AdamW(gpt_new.parameters(), lr=training_args.learning_rate,\n",
        "                                  betas=(training_args.adam_beta1, training_args.adam_beta2), \n",
        "                                  weight_decay=training_args.adam_epsilon)\n",
        "\n",
        "    train_data_loader = dataloaders['train']\n",
        "    eval_data_loader = dataloaders['eval']\n",
        "\n",
        "    max_patience = 2\n",
        "    last_loss = 1000000\n",
        "    PATH = f\"./models/gpt_new.pt\"\n",
        "    for epoch in range(max_epochs):\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        # training\n",
        "        train_test(gpt_new, train_data_loader, optimizer, training=\"train\")\n",
        "        # validation at end of epoch\n",
        "        with torch.no_grad():\n",
        "            validation_loss = train_test(gpt_new, eval_data_loader, optimizer, training=\"validation\")\n",
        "\n",
        "        if validation_loss < last_loss:\n",
        "            last_loss = validation_loss\n",
        "            current_patience = 0\n",
        "        else:\n",
        "            if current_patience == 0:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': gpt_new.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': last_loss,\n",
        "                    }, PATH)\n",
        "            current_patience += 1\n",
        "        if current_patience == max_patience:\n",
        "            break\n",
        "\n",
        "    # # Testing once patience is reached\n",
        "    # torch.manual_seed(seed)\n",
        "    # model = TuneableModel(input_size, parameters[\"hidden_size\"], parameters[\"dropout\"], parameters[\"n_hidden\"])\n",
        "    # gpt_new.to(device)\n",
        "    # optimizer = torch.optim.AdamW(model.parameters(), lr=parameters[\"learning_rate\"], betas=(0.99, 0.99), weight_decay=1e-4)\n",
        "    # checkpoint = torch.load(PATH)\n",
        "    # model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    # with torch.no_grad():\n",
        "    #     prediction_list, label_list = train_test(model, test_dataloader, optimizer, training=\"test\")\n",
        "    # predictions.extend(prediction_list)\n",
        "    # labels.extend(label_list)\n",
        "\n",
        "    return #compute_metrics() # insert sari ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aE6UMZqHEk6l",
        "outputId": "b978ad6d-cb06-4e91-bfcb-b1f86e73470b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2540 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2540 [01:10<49:24:05, 70.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sari': 26.463381547900582}\n",
            "forward\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/2540 [02:08<44:29:26, 63.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sari': 27.814140879197552}\n",
            "forward\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "evaluate(dataloaders, training_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sari': 75.0}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sari.compute(sources=[\"the lion\"], predictions=['the witch'], references=[['and the wardrobe']])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08e2d36688ca4570a58f2cf6ecc31660": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aca0d72fffa4bde8e8dd52af9cff9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85ce6a9a3e04c40b7c01ea253cb489c",
            "placeholder": "​",
            "style": "IPY_MODEL_c16270989c4a42bdaad5b8d798b67f44",
            "value": " 20313/20313 [00:12&lt;00:00, 1613.93 examples/s]"
          }
        },
        "2fef12b0bf154bcb96af91c2b7aeac9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b02b3f357b48958c5b5a9560230ba5",
            "max": 20313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3ce635eb26e455799bba15b03bc2680",
            "value": 20313
          }
        },
        "40ad8ad5dbbc448d9ce9b88f3c950233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dc2f24808444c2e8fe361b805540536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e2d36688ca4570a58f2cf6ecc31660",
            "placeholder": "​",
            "style": "IPY_MODEL_40ad8ad5dbbc448d9ce9b88f3c950233",
            "value": "Map: 100%"
          }
        },
        "70b6190d0ac34cbab2e2d679edfb5e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b634c856a1d9485bab369cbb6e0e1a4b",
            "placeholder": "​",
            "style": "IPY_MODEL_9aa23785abf74453af9f16289d74e485",
            "value": " 5079/5079 [00:03&lt;00:00, 1240.82 examples/s]"
          }
        },
        "7cbc2f511cfa4d24823990f1f8f99285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ffe83e3794e465bbaf0263add300d1e",
            "max": 5079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b0cdf891dfe4f88994737144f2e9d6c",
            "value": 5079
          }
        },
        "7ffe83e3794e465bbaf0263add300d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0cdf891dfe4f88994737144f2e9d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9946327fc8484a899eeade3d04b3ebf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa23785abf74453af9f16289d74e485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3ce635eb26e455799bba15b03bc2680": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4fc45c1a950454fbb3cafbfe4893681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c78098600100460483ac0587a8c19c71",
              "IPY_MODEL_2fef12b0bf154bcb96af91c2b7aeac9d",
              "IPY_MODEL_1aca0d72fffa4bde8e8dd52af9cff9f9"
            ],
            "layout": "IPY_MODEL_fc119722a901433a851416f9fbb6586c"
          }
        },
        "b634c856a1d9485bab369cbb6e0e1a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fa656ecfff42e7b4267cc27d711025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c16270989c4a42bdaad5b8d798b67f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4b02b3f357b48958c5b5a9560230ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78098600100460483ac0587a8c19c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe51e1dd6e8f43e6a1e5639552d64baa",
            "placeholder": "​",
            "style": "IPY_MODEL_c0fa656ecfff42e7b4267cc27d711025",
            "value": "Map: 100%"
          }
        },
        "d85ce6a9a3e04c40b7c01ea253cb489c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88ca4ace1714f808dd316b0e201c70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dc2f24808444c2e8fe361b805540536",
              "IPY_MODEL_7cbc2f511cfa4d24823990f1f8f99285",
              "IPY_MODEL_70b6190d0ac34cbab2e2d679edfb5e4c"
            ],
            "layout": "IPY_MODEL_9946327fc8484a899eeade3d04b3ebf0"
          }
        },
        "fc119722a901433a851416f9fbb6586c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe51e1dd6e8f43e6a1e5639552d64baa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
