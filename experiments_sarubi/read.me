Steps to do:

1. clone https://github.com/hiyouga/LLaMA-Factory
2. first you can run htcondor run.sh script only to install llama-factory
3. once installation success, you can comment those and directly activate your conda env.
4. to do lora fine-tuning: examples/train_lora/llama3_lora_sft.yaml
    4.1- prepare your dataset. you probably have to spend sometime here. you need to add your dataset name here: data/dataset_info.json
    dataset has to be json file that has sample like: data/alpaca_en_demo.json
    {
    "instruction": "prompt to rewrite for grade-?",
    "input": "your complex sentence",
    "output": "your simple sentence for the target grade-?."
    }
    once you prepare your dataset and added dataset_info.json
    4.2- update llama.yaml confing file with all the relevant parameters. besides, you can add any params that support by HF tranier.
5. fine-tune it.
6. since the objective now is to rewrite, you can directly evaluate against SARI or FKGL etc. rather than perplexity.