{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing the data for building the datasets from \"\"\"\n",
    "# # !pip install friends\n",
    "\n",
    "\n",
    "# train_info = pd.read_csv('./data/wikilarge/grade_ratio_wiki_train.csv')\n",
    "# val_info = pd.read_csv('./data/wikilarge/grade_ratio_wiki_val.csv')\n",
    "# test_info = pd.read_csv('./data/wikilarge/grade_ratio_wiki_test.csv')\n",
    "\n",
    "# with open('./data/wikilarge/wiki_train.src', 'r', encoding='utf-8') as f:\n",
    "#     train_src = pd.DataFrame(f.readlines(), columns=['src'])\n",
    "# with open('./data/wikilarge/wiki_val.src', 'r', encoding='utf-8') as f:\n",
    "#     val_src = pd.DataFrame(f.readlines(), columns=['src'])\n",
    "# with open('./data/wikilarge/wiki_test.src', 'r', encoding='utf-8') as f:\n",
    "#     test_src = pd.DataFrame(f.readlines(), columns=['src'])\n",
    "\n",
    "# with open('./data/wikilarge/wiki_train.tgt', 'r', encoding='utf-8') as f:\n",
    "#     train_tgt = pd.DataFrame(f.readlines(), columns=['tgt'])\n",
    "# with open('./data/wikilarge/wiki_val.tgt', 'r', encoding='utf-8') as f:\n",
    "#     val_tgt = pd.DataFrame(f.readlines(), columns=['tgt'])\n",
    "# with open('./data/wikilarge/wiki_test.tgt', 'r', encoding='utf-8') as f:\n",
    "#     test_tgt = pd.DataFrame(f.readlines(), columns=['tgt'])\n",
    "\n",
    "# train_data = pd.concat([train_info, train_src, train_tgt], axis=1)\n",
    "# val_data = pd.concat([val_info, val_src, val_tgt], axis=1)\n",
    "# test_data = pd.concat([test_info, test_src, test_tgt], axis=1)\n",
    "\n",
    "# all_data = pd.concat([train_data, val_data, test_data], axis=0)\n",
    "# # subset to src tgt and grade\n",
    "# all_data = all_data[['src', 'tgt', 'abs_tgt_FKGL_Grade', 'abs_src_FKGL_Grade']]\n",
    "# # drop duplicates\n",
    "# all_data = all_data[all_data['src'] != all_data['tgt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (292194, 36)\n",
      "Group 0 - Train size: 960, Test/Val size: 1024\n",
      "Group 1 - Train size: 896, Test/Val size: 1024\n",
      "Group 2 - Train size: 4832, Test/Val size: 1024\n",
      "Group 3 - Train size: 5984, Test/Val size: 1024\n",
      "Group 4 - Train size: 18016, Test/Val size: 1024\n",
      "Group 5 - Train size: 13856, Test/Val size: 1024\n",
      "Group 6 - Train size: 30080, Test/Val size: 1024\n",
      "Group 7 - Train size: 23552, Test/Val size: 1024\n",
      "Group 8 - Train size: 31456, Test/Val size: 1024\n",
      "Group 9 - Train size: 22016, Test/Val size: 1024\n",
      "Group 10 - Train size: 32576, Test/Val size: 1024\n",
      "Group 11 - Train size: 18016, Test/Val size: 1024\n",
      "Group 12 - Train size: 23584, Test/Val size: 1024\n",
      "Group 13 - Train size: 51808, Test/Val size: 1024\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 960\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 0 created with lengths: train=960, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 896\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 1 created with lengths: train=896, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 4832\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 2 created with lengths: train=4832, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 5984\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 3 created with lengths: train=5984, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 18016\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 4 created with lengths: train=18016, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 13856\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 5 created with lengths: train=13856, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 30080\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 6 created with lengths: train=30080, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 23552\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 7 created with lengths: train=23552, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 31456\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 8 created with lengths: train=31456, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 22016\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 9 created with lengths: train=22016, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 32576\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 10 created with lengths: train=32576, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 18016\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 11 created with lengths: train=18016, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 23584\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 12 created with lengths: train=23584, val=512, test=512\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 51808\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['src', 'tgt', 'current_line', 'New Line', 'Line', 'abs_src_Length', 'abs_src_MaxDepDepth', 'abs_src_MaxDepLength', 'abs_src_DiffWords', 'abs_src_Leven', 'abs_src_WordCount', 'abs_tgt_Length', 'abs_tgt_MaxDepDepth', 'abs_tgt_MaxDepLength', 'abs_tgt_DiffWords', 'abs_tgt_Leven', 'abs_tgt_WordCount', 'Length_ratio', 'MaxDepDepth_ratio', 'MaxDepLength_ratio', 'DiffWords_ratio', 'Leven_ratio', 'WordCount_ratio', 'abs_src_FreqRank', 'abs_tgt_FreqRank', 'FreqRank_ratio', 'abs_src_FKGL_Grade', 'abs_tgt_FKGL_Grade', 'FKGL_Grade_ratio', 'abs_src_ARI_Grade', 'abs_tgt_ARI_Grade', 'ARI_Grade_ratio', 'similarity', 'grade_diff', 'length_difference_ratio', 'label'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n",
      "Dataset for group 13 created with lengths: train=51808, val=512, test=512\n"
     ]
    }
   ],
   "source": [
    "\"\"\"For building the pickle files for each grade from original CSV files\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from datasets import DatasetDict, Dataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv('data/wikilarge/intermediate/wiki_cleaned_doubled.csv')\n",
    "print(f\"Loaded data shape: {all_data.shape}\")\n",
    "\n",
    "groups = all_data.groupby('abs_tgt_FKGL_Grade')\n",
    "\n",
    "group_dict = defaultdict()\n",
    "split_dict = defaultdict()\n",
    "for group in groups:\n",
    "    group_dict[group[0]] = group[1].reset_index(drop=True)\n",
    "\n",
    "for group in group_dict.keys():\n",
    "    train, test_val = train_test_split(group_dict[group], test_size=1024, random_state=42,)\n",
    "    train_size = (train.shape[0] // 32 ) * 32\n",
    "    assert train_size % 32 == 0, \"Train size must be a multiple of 32\"\n",
    "    train = train.iloc[:train_size]  # ensure train size is a multiple of 32\n",
    "    print(f\"Group {group} - Train size: {train.shape[0]}, Test/Val size: {test_val.shape[0]}\")\n",
    "    val, test = train_test_split(test_val, test_size=0.5, random_state=42)\n",
    "    split_dict[group] = {'train': train.reset_index(drop=True), 'val': val.reset_index(drop=True), 'test': test.reset_index(drop=True)}\n",
    "\n",
    "# convert dataframes to datasets and save to pickle format\n",
    "for group in split_dict.keys():\n",
    "    train_data = Dataset.from_pandas(split_dict[group]['train'])\n",
    "    val_data = Dataset.from_pandas(split_dict[group]['val'])\n",
    "    test_data = Dataset.from_pandas(split_dict[group]['test'])\n",
    "    dataset_dict = DatasetDict({'train': train_data, 'val': val_data, 'test': test_data})\n",
    "    print(dataset_dict)\n",
    "    print(f\"Dataset for group {group} created with lengths: train={len(train_data)}, val={len(val_data)}, test={len(test_data)}\")\n",
    "    with open(f'data/wikilarge/intermediate/grade_{group}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataset_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:04<00:53,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 0 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade0_alpaca and uploaded to williamplacroix/wikilarge_grade0_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:08<00:50,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 1 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade1_alpaca and uploaded to williamplacroix/wikilarge_grade1_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:14<00:54,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 2 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade2_alpaca and uploaded to williamplacroix/wikilarge_grade2_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [00:20<00:56,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 3 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade3_alpaca and uploaded to williamplacroix/wikilarge_grade3_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 5.43M/5.43M [00:01<00:00, 3.10MB/s]\n",
      " 36%|███▌      | 5/14 [00:33<01:12,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 4 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade4_alpaca and uploaded to williamplacroix/wikilarge_grade4_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 4.48M/4.48M [00:01<00:00, 3.03MB/s]\n",
      " 43%|████▎     | 6/14 [01:00<01:57, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 5 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade5_alpaca and uploaded to williamplacroix/wikilarge_grade5_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 9.89M/9.89M [00:03<00:00, 3.20MB/s]\n",
      " 50%|█████     | 7/14 [01:19<01:53, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 6 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade6_alpaca and uploaded to williamplacroix/wikilarge_grade6_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 8.02M/8.02M [00:02<00:00, 3.05MB/s]\n",
      " 57%|█████▋    | 8/14 [01:43<01:50, 18.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 7 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade7_alpaca and uploaded to williamplacroix/wikilarge_grade7_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 11.2M/11.2M [00:02<00:00, 4.46MB/s]\n",
      " 64%|██████▍   | 9/14 [02:32<02:20, 28.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 8 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade8_alpaca and uploaded to williamplacroix/wikilarge_grade8_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 8.04M/8.04M [00:01<00:00, 4.16MB/s]\n",
      " 71%|███████▏  | 10/14 [03:14<02:09, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 9 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade9_alpaca and uploaded to williamplacroix/wikilarge_grade9_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 12.2M/12.2M [00:02<00:00, 4.52MB/s]\n",
      " 79%|███████▊  | 11/14 [03:45<01:35, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 10 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade10_alpaca and uploaded to williamplacroix/wikilarge_grade10_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [04:00<00:53, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 11 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade11_alpaca and uploaded to williamplacroix/wikilarge_grade11_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [04:20<00:24, 24.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 12 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade12_alpaca and uploaded to williamplacroix/wikilarge_grade12_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.json: 100%|██████████| 23.8M/23.8M [00:05<00:00, 4.37MB/s]\n",
      "100%|██████████| 14/14 [05:02<00:00, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade 13 processed and saved to data/wikilarge/cleaned_graded_splits/wikilarge_grade13_alpaca and uploaded to williamplacroix/wikilarge_grade13_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import pickle, convert back to dataframe, export as json in alpaca format\"\"\"\n",
    "import os\n",
    "from datasets import DatasetDict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from huggingface_hub import login, HfApi\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "login(token=token)\n",
    "\n",
    "def reimport_and_save_as_json(grade):\n",
    "    # Load the pickled dataset\n",
    "\n",
    "    #system_prompt = \"Please rewrite the following sentence to make it easily understandable by students in Grade {tgt_ideal_Grade}. Ensure that the rewritten sentence is grammatically correct, fluent, and retains the core message of the original sentence without changing its meaning.\"\n",
    "    instruction_prompt = \"Rewrite this Input sentence to make it easily understandable by students in Grade {tgt_ideal_Grade}\"# while preserving the meaning: Please note, if the initial rewrite does not meet the specified grade level, you are encouraged to modify and regenerate the output until the criteria are satisfactorily met. The final output should only include the last, correct version of the rewritten sentence(s).\"\n",
    "    \n",
    "    with open(f'./data/wikilarge/intermediate/grade_{grade}.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    dataset = DatasetDict()\n",
    "    \n",
    "    for split_str in [\"train\", \"val\", \"test\"]:\n",
    "        split = pd.DataFrame(data[split_str])\n",
    "        split['input'] = split['src'].apply(lambda x: x.strip())\n",
    "        split['output'] = split['tgt'].apply(lambda x: x.strip())\n",
    "\n",
    "        #split['system'] = split.apply(lambda x: system_prompt.format(tgt_ideal_Grade=grade), axis=1)\n",
    "        split['instruction'] = split.apply(lambda x: instruction_prompt.format(tgt_ideal_Grade=grade), axis=1)\n",
    "  \n",
    "        split['src_grade'] = split['abs_src_FKGL_Grade']\n",
    "        split['tgt_grade'] = split['abs_tgt_FKGL_Grade']\n",
    "\n",
    "        split = split[['input', 'output', 'instruction']]#, 'system']]#, 'src_grade', 'tgt_grade']]\n",
    "        if split_str == 'val':\n",
    "            split_str = 'validate'\n",
    "        \n",
    "        dataset[split_str] = Dataset.from_pandas(split)\n",
    "    \n",
    "    # Save as Alpaca-formatted JSON\n",
    "    path = f'data/wikilarge/cleaned_graded_splits/wikilarge_grade{grade}_alpaca'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for split_str in [\"train\", \"validate\", \"test\"]:\n",
    "        pd.DataFrame(dataset[split_str]).to_json(f'{path}/{split_str}.json', orient='records', indent=2)\n",
    "    \n",
    "    # Upload JSON files directly to hub to maintain JSON format\n",
    "    api = HfApi()\n",
    "    repo_id = f'williamplacroix/wikilarge_grade{grade}_alpaca'\n",
    "    \n",
    "    # # Create repo if it doesn't exist\n",
    "    try:\n",
    "        api.create_repo(repo_id=repo_id, private=True, exist_ok=True, repo_type=\"dataset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Repo creation note: {e}\")\n",
    "    \n",
    "    # Upload each JSON file\n",
    "    for split_str in [\"train\", \"validate\", \"test\"]:\n",
    "        try:\n",
    "            api.delete_file(\n",
    "                path_in_repo=f'{split_str}.json',\n",
    "                repo_id=repo_id,\n",
    "                repo_type=\"dataset\",  # or \"model\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"nothing to delete: {e}\")\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=f'{path}/{split_str}.json',\n",
    "            path_in_repo=f'{split_str}.json',\n",
    "            repo_id=repo_id,\n",
    "            commit_message=f\"Update {split_str} split\",\n",
    "            repo_type=\"dataset\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Grade {grade} processed and saved to {path} and uploaded to {repo_id}\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "# test with grade 8\n",
    "for grade in tqdm({0,1,2,3,4,5,6,7,8,9,10,11,12,13}):\n",
    "    reimport_and_save_as_json(grade)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
