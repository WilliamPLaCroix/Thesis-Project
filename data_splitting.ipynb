{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing the data for building the datasets from \"\"\"\n",
    "# # !pip install friends\n",
    "# import pandas as pd\n",
    "\n",
    "# train_info = pd.read_csv('./data/wikilarge/grade_ratio_wiki_train.csv')\n",
    "# val_info = pd.read_csv('./data/wikilarge/grade_ratio_wiki_val.csv')\n",
    "# test_info = pd.read_csv('./data/wikilarge/grade_ratio_wiki_test.csv')\n",
    "\n",
    "# with open('./data/wikilarge/wiki_train.src', 'r', encoding='utf-8') as f:\n",
    "#     train_src = pd.DataFrame(f.readlines(), columns=['src'])\n",
    "# with open('./data/wikilarge/wiki_val.src', 'r', encoding='utf-8') as f:\n",
    "#     val_src = pd.DataFrame(f.readlines(), columns=['src'])\n",
    "# with open('./data/wikilarge/wiki_test.src', 'r', encoding='utf-8') as f:\n",
    "#     test_src = pd.DataFrame(f.readlines(), columns=['src'])\n",
    "\n",
    "# with open('./data/wikilarge/wiki_train.tgt', 'r', encoding='utf-8') as f:\n",
    "#     train_tgt = pd.DataFrame(f.readlines(), columns=['tgt'])\n",
    "# with open('./data/wikilarge/wiki_val.tgt', 'r', encoding='utf-8') as f:\n",
    "#     val_tgt = pd.DataFrame(f.readlines(), columns=['tgt'])\n",
    "# with open('./data/wikilarge/wiki_test.tgt', 'r', encoding='utf-8') as f:\n",
    "#     test_tgt = pd.DataFrame(f.readlines(), columns=['tgt'])\n",
    "\n",
    "# train_data = pd.concat([train_info, train_src, train_tgt], axis=1)\n",
    "# val_data = pd.concat([val_info, val_src, val_tgt], axis=1)\n",
    "# test_data = pd.concat([test_info, test_src, test_tgt], axis=1)\n",
    "\n",
    "# all_data = pd.concat([train_data, val_data, test_data], axis=0)\n",
    "# # subset to src tgt and grade\n",
    "# all_data = all_data[['src', 'tgt', 'abs_tgt_FKGL_Grade', 'abs_src_FKGL_Grade']]\n",
    "# # drop duplicates\n",
    "# all_data = all_data[all_data['src'] != all_data['tgt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though founded in 1887, under Jack Hyles' leadership from 1959 & ndash; 2001 it became one of the megachurches in the United States and during the 1970s had the highest Sunday school attendance of any church in the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"For building the pickle files for each grade from original CSV files\"\"\"\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from collections import defaultdict\n",
    "# from datasets import DatasetDict, Dataset\n",
    "# import pickle\n",
    "# groups = all_data.groupby('abs_tgt_FKGL_Grade')\n",
    "\n",
    "# group_dict = defaultdict()\n",
    "# split_dict = defaultdict()\n",
    "# for group in groups:\n",
    "#     group_dict[group[0]] = group[1].reset_index(drop=True)\n",
    "# print(group_dict[0].src[0])\n",
    "\n",
    "# for group in group_dict.keys():\n",
    "#     train, test_val = train_test_split(group_dict[group], test_size=1000, random_state=42,)\n",
    "#     val, test = train_test_split(test_val, test_size=0.5, random_state=42)\n",
    "#     split_dict[group] = {'train': train.reset_index(drop=True), 'val': val.reset_index(drop=True), 'test': test.reset_index(drop=True)}\n",
    "\n",
    "\n",
    "# # convert dataframes to datasets and save to pickle format\n",
    "# for group in split_dict.keys():\n",
    "#     train_data = Dataset.from_pandas(split_dict[group]['train'])\n",
    "#     val_data = Dataset.from_pandas(split_dict[group]['val'])\n",
    "#     test_data = Dataset.from_pandas(split_dict[group]['test'])\n",
    "#     dataset_dict = DatasetDict({'train': train_data, 'val': val_data, 'test': test_data})\n",
    "\n",
    "#     with open(f'./data/wikilarge/graded_splits/grade_{group}.pkl', 'wb') as f:\n",
    "#         pickle.dump(dataset_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:12<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import pickle, convert back to dataframe, export as json in alpaca format\"\"\"\n",
    "import os\n",
    "from datasets import DatasetDict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def reimport_and_save_as_json(grade):\n",
    "    # Load the pickled dataset\n",
    "\n",
    "    #system_prompt = \"Please rewrite the following sentence to make it easily understandable by students in Grade {tgt_ideal_Grade}. Ensure that the rewritten sentence is grammatically correct, fluent, and retains the core message of the original sentence without changing its meaning.\"\n",
    "    instruction_prompt = \"Rewrite this Input sentence to make it easily understandable by students in Grade {tgt_ideal_Grade}\"# while preserving the meaning: Please note, if the initial rewrite does not meet the specified grade level, you are encouraged to modify and regenerate the output until the criteria are satisfactorily met. The final output should only include the last, correct version of the rewritten sentence(s).\"\n",
    "    \n",
    "    with open(f'./data/wikilarge/graded_splits_old/picklefiles/grade_{grade}.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    dataset = DatasetDict()\n",
    "    \n",
    "    for split_str in [\"train\", \"val\", \"test\"]:\n",
    "        split = pd.DataFrame(data[split_str])\n",
    "        split['input'] = split['src'].apply(lambda x: x.strip())\n",
    "        split['output'] = split['tgt'].apply(lambda x: x.strip())\n",
    "\n",
    "        #split['system'] = split.apply(lambda x: system_prompt.format(tgt_ideal_Grade=grade), axis=1)\n",
    "        split['instruction'] = split.apply(lambda x: instruction_prompt.format(tgt_ideal_Grade=grade), axis=1)\n",
    "  \n",
    "        split['src_grade'] = split['abs_src_FKGL_Grade']\n",
    "        split['tgt_grade'] = split['abs_tgt_FKGL_Grade']\n",
    "\n",
    "        split = split[['input', 'output', 'instruction']]#, 'system']]#, 'src_grade', 'tgt_grade']]\n",
    "\n",
    "        dataset[split_str] = split\n",
    "\n",
    "    # Save as Alpaca-formatted JSON\n",
    "    path = f'./data/wikilarge/graded_splits_new/grade_{grade}'\n",
    "    #os.mkdir(path)\n",
    "    for split_str in [\"train\", \"val\", \"test\"]:\n",
    "        \n",
    "        pd.DataFrame(dataset[split_str]).to_json(f'{path}/{split_str}.json', orient='records', indent=2)\n",
    "\n",
    "from tqdm import tqdm\n",
    "# test with grade 8\n",
    "for grade in tqdm({2,3,4,5,6,7,8,9,10,11,12}):\n",
    "    reimport_and_save_as_json(grade)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
