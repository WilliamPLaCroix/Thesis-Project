{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorWithPadding, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from evaluate import load\n",
    "sari = load(\"sari\")\n",
    "\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = './data/wikilarge/'\n",
    "#training_args = TrainingArguments(\"test=trainer\", evaluation_strategy=\"epoch\")#TrainingArguments(output_dir=f\"{data_location}training_args\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy='steps',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    output_dir='./out',\n",
    "    logging_steps=100,\n",
    "    save_steps=3000,\n",
    "    eval_steps=10000,\n",
    "    warmup_steps=2000,\n",
    "    gradient_accumulation_steps=1,\n",
    "    save_total_limit=3,\n",
    "    include_inputs_for_metrics = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_ratio = pd.read_csv(f'{data_location}grade_ratio_wiki_train.csv')\n",
    "# source texts\n",
    "with open(f'{data_location}wiki_train.src', 'r', encoding='utf-8') as f:\n",
    "    train_src = f.readlines()\n",
    "train_src = pd.DataFrame(train_src, columns=['source'])\n",
    "# target texts\n",
    "with open(f'{data_location}wiki_train.tgt', 'r', encoding='utf-8') as f:\n",
    "    train_tgt = f.readlines()\n",
    "train_tgt = pd.DataFrame(train_tgt, columns=['target'])\n",
    "train_texts = pd.concat([train_src, grade_ratio['abs_src_FKGL_Grade'], train_tgt, grade_ratio['abs_tgt_FKGL_Grade']], axis=1)\n",
    "train_texts.rename(columns={'abs_src_FKGL_Grade': 'source_grade', 'abs_tgt_FKGL_Grade': 'target_grade'}, inplace=True)\n",
    "train_texts['souce'] = train_texts['source'].replace(r'\\n',' ', regex=True)\n",
    "train_texts['target'] = train_texts['target'].replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heinrich Luitpold Himmler (7 October 1900 - 23 May 1945) was Chief of the German Police and Minister of the Interior.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = pd.read_pickle(f'{data_location}train_texts.pkl')\n",
    "train_texts.iloc[0]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>source_grade</th>\n",
       "      <th>target</th>\n",
       "      <th>target_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Though founded in 1887, under Jack Hyles' lead...</td>\n",
       "      <td>13</td>\n",
       "      <td>Dr. Jack Hyles\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>On January 27, 2008, at the NHL All-Star Game ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Records\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Gone the times when nations battled for this' ...</td>\n",
       "      <td>8</td>\n",
       "      <td>gone the days when strife and discord.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>May 17 &amp; ndash; The conflict between Toyotomi ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Ghent falls to the Spanish.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Some subjects that are discussed have criminal...</td>\n",
       "      <td>11</td>\n",
       "      <td>(see and).\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216813</th>\n",
       "      <td>Dubnium (,) is a chemical element with the sym...</td>\n",
       "      <td>10</td>\n",
       "      <td>It has the symbol Db.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216828</th>\n",
       "      <td>WWE Hell in a Cell is a professional wrestling...</td>\n",
       "      <td>13</td>\n",
       "      <td>Hell\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216833</th>\n",
       "      <td>He died of a heart attack in 1968 and was hono...</td>\n",
       "      <td>8</td>\n",
       "      <td>He died from a heart attack in 1968.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216839</th>\n",
       "      <td>In English, the name is sometimes spelled Bela...</td>\n",
       "      <td>10</td>\n",
       "      <td>-)\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216850</th>\n",
       "      <td>Such desks are sometimes called left-pedestal ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Desks can be used at home.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10990 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   source  source_grade  \\\n",
       "5       Though founded in 1887, under Jack Hyles' lead...            13   \n",
       "121     On January 27, 2008, at the NHL All-Star Game ...             7   \n",
       "130     Gone the times when nations battled for this' ...             8   \n",
       "152     May 17 & ndash; The conflict between Toyotomi ...            10   \n",
       "172     Some subjects that are discussed have criminal...            11   \n",
       "...                                                   ...           ...   \n",
       "216813  Dubnium (,) is a chemical element with the sym...            10   \n",
       "216828  WWE Hell in a Cell is a professional wrestling...            13   \n",
       "216833  He died of a heart attack in 1968 and was hono...             8   \n",
       "216839  In English, the name is sometimes spelled Bela...            10   \n",
       "216850  Such desks are sometimes called left-pedestal ...             5   \n",
       "\n",
       "                                          target  target_grade  \n",
       "5                               Dr. Jack Hyles\\n             0  \n",
       "121                                    Records\\n             0  \n",
       "130     gone the days when strife and discord.\\n             0  \n",
       "152                Ghent falls to the Spanish.\\n             0  \n",
       "172                                 (see and).\\n             0  \n",
       "...                                          ...           ...  \n",
       "216813                   It has the symbol Db.\\n             0  \n",
       "216828                                    Hell\\n             0  \n",
       "216833    He died from a heart attack in 1968.\\n             0  \n",
       "216839                                      -)\\n             0  \n",
       "216850              Desks can be used at home.\\n             0  \n",
       "\n",
       "[10990 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_groups = train_texts.groupby(['target_grade'])\n",
    "grade_groups.get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target', 'target_grade', '__index_level_0__'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target', 'target_grade', '__index_level_0__'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create custom dataset where each grade group is a separate dataset, including source, target, and target grade\n",
    "datasets = {}\n",
    "for i, (grade, group) in enumerate(grade_groups):\n",
    "    datasets[i] = Dataset.from_pandas(group[['source', 'target', 'target_grade']]).train_test_split(test_size=0.2)\n",
    "\n",
    "datasets[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Thus, taekwondo may be loosely translated as \"the art of the foot and fist\" or \"the art of kicking and punching.\"\\n',\n",
       " 'target': 'Taekwondo can therefore be translated as \"way of the foot and of the fist\".\\n',\n",
       " 'target_grade': 6,\n",
       " '__index_level_0__': 6800}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[6]['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a781517bf64a5d8a6f725f320b49d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7613931bb09a4c098479b6ff4b8637e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target', 'target_grade', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'target', 'target_grade', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(text=examples[\"source\"], text_target=examples['target'], padding=\"max_length\", max_length=64, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_dataset_6 = datasets[6].map(tokenize_function, batched=True)\n",
    "tokenized_dataset_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The female alternatives are Khatun and Khanum.\\n']\n",
      "['The female alternative are Khatun and Khanum.\\n']\n",
      "[4463]\n",
      "[[464, 4048, 14693, 389, 509, 5183, 403, 290, 11356, 388, 13, 198, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]\n",
      "[[464, 4048, 5559, 389, 509, 5183, 403, 290, 11356, 388, 13, 198, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]\n"
     ]
    }
   ],
   "source": [
    "for feature in tokenized_dataset_6['train'][1]:\n",
    "    if feature not in {'attention_mask', 'target_grade', 'text', 'text_target'}:\n",
    "        print([tokenized_dataset_6['train'][1][feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m     source_str \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(source_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sari\u001b[38;5;241m.\u001b[39mcompute(sources\u001b[38;5;241m=\u001b[39msource_str, references\u001b[38;5;241m=\u001b[39mlabel_str, predictions\u001b[38;5;241m=\u001b[39mpred_str)\n\u001b[1;32m---> 16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset_6\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset_6\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     28\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/gpt2_wikilarge_6\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\transformers\\trainer_seq2seq.py:56\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     44\u001b[0m     model: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, nn\u001b[38;5;241m.\u001b[39mModule] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     preprocess_logits_for_metrics: Optional[Callable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m ):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\transformers\\trainer.py:533\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    531\u001b[0m default_callbacks \u001b[38;5;241m=\u001b[39m DEFAULT_CALLBACKS \u001b[38;5;241m+\u001b[39m get_reporting_integration_callbacks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mreport_to)\n\u001b[0;32m    532\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m default_callbacks \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_callbacks \u001b[38;5;241m+\u001b[39m callbacks\n\u001b[1;32m--> 533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler \u001b[38;5;241m=\u001b[39m \u001b[43mCallbackHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_callback(PrinterCallback \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdisable_tqdm \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_PROGRESS_CALLBACK)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# Will be set to True by `self._setup_loggers()` on first call to `self.log()`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\transformers\\trainer_callback.py:313\u001b[0m, in \u001b[0;36mCallbackHandler.__init__\u001b[1;34m(self, callbacks, model, tokenizer, optimizer, lr_scheduler)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\transformers\\trainer_callback.py:330\u001b[0m, in \u001b[0;36mCallbackHandler.add_callback\u001b[1;34m(self, callback)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m, callback):\n\u001b[1;32m--> 330\u001b[0m     cb \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callback, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m callback\n\u001b[0;32m    331\u001b[0m     cb_class \u001b[38;5;241m=\u001b[39m callback \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callback, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m callback\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb_class \u001b[38;5;129;01min\u001b[39;00m [c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks]:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:675\u001b[0m, in \u001b[0;36mWandbCallback.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWandbCallback requires wandb to be installed. Run `pip install wandb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_wandb:\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb \u001b[38;5;241m=\u001b[39m wandb\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\__init__.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# This needs to be early as other modules call it.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mterm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m termsetup, termlog, termerror, termwarn\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdk \u001b[38;5;28;01mas\u001b[39;00m wandb_sdk\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m     31\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwandb_lib \u001b[38;5;241m=\u001b[39m wandb_sdk\u001b[38;5;241m.\u001b[39mlib\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\__init__.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_alerts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlertLevel  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_init\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _attach, init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_login\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_require\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_artifact_representation\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wandb_login, wandb_setup\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Backend\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     RunDisabled,\n\u001b[0;32m     35\u001b[0m     SummaryDisabled,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     telemetry,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Deprecated, deprecate\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\backend\\backend.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterfaceBase\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface_queue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterfaceQueue\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wandb_internal\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings_static\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SettingsStatic\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmailbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mailbox\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\internal\\internal.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface_queue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterfaceQueue\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracelog\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context, handler, internal_util, sender, writer\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqueue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Queue\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\internal\\handler.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context, sample, tb_watcher\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings_static\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SettingsStatic\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystem_monitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SystemMonitor\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_internal_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricSummary\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\internal\\system\\system_monitor.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict, deque\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Deque, Dict, List, Optional, Tuple\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masset_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asset_registry\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Asset, Interface\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopen_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenMetrics\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\internal\\system\\assets\\__init__.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Disk\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPU\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu_amd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPUAMD\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu_apple\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPUApple\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IPU\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\wandb\\sdk\\internal\\system\\assets\\gpu_amd.py:28\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings_static\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SettingsStatic\n\u001b[0;32m     27\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m ROCM_SMI_CMD: Final[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhich\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrocm-smi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/bin/rocm-smi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rocm_smi_stats\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m     32\u001b[0m     command \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(ROCM_SMI_CMD), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-a\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--json\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\shutil.py:1528\u001b[0m, in \u001b[0;36mwhich\u001b[1;34m(cmd, mode, path)\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m thefile \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m   1527\u001b[0m             name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, thefile)\n\u001b[1;32m-> 1528\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _access_check(name, mode):\n\u001b[0;32m   1529\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m name\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_metrics(prediction):\n",
    "    source_ids = prediction.input_ids\n",
    "    labels_ids = prediction.label_ids\n",
    "    pred_ids = prediction.predictions\n",
    "    \n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    source_str = tokenizer.batch_decode(source_ids, skip_special_tokens=True)\n",
    "\n",
    "    return sari.compute(sources=source_str, references=label_str, predictions=pred_str)\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_6['train'],\n",
    "    eval_dataset=tokenized_dataset_6['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model('./models/gpt2_wikilarge_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum mechanics is a fundamental theory in physics that provides a description of the physical properties \n",
      "of nature at the scale of atoms and subatomic particles. It is the foundation of all quantum physics including \n",
      "quantum chemistry, quantum field theory, quantum technology, and quantum information science\n",
      "\n",
      "\n",
      "Quantum mechanics is a fundamental theory in physics that provides a description of the physical properties \n",
      "of nature at the scale of atoms and subatomic particles. It is the foundation of all quantum physics including \n",
      "quantum chemistry, quantum field theory, quantum technology, and quantum information science\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = '''\n",
    "Quantum mechanics is a fundamental theory in physics that provides a description of the physical properties \n",
    "of nature at the scale of atoms and subatomic particles. It is the foundation of all quantum physics including \n",
    "quantum chemistry, quantum field theory, quantum technology, and quantum information science\n",
    "'''\n",
    "\n",
    "trained_model = AutoModelForCausalLM.from_pretrained('./models/gpt2_wikilarge_6')\n",
    "inputs = tokenizer([input_text], padding='max_length',\n",
    "                       max_length=60, truncation=True, return_tensors='pt')\n",
    "\n",
    "trained_model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "trained_model.config.eos_token_id = tokenizer.sep_token_id\n",
    "trained_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "#trained_model.config.vocab_size = model.config.encoder.vocab_size\n",
    "\n",
    "output = trained_model.generate(inputs['input_ids'],\n",
    "                        max_length=100,\n",
    "                        min_length=30,\n",
    "                        num_beams=1,\n",
    "                        length_penalty=0.8,\n",
    "                        temperature=1.0,\n",
    "                        early_stopping=True,\n",
    "                        top_k=50,\n",
    "                        do_sample=False)\n",
    "\n",
    "text = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "print(input_text)\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.093913043478263"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = Readability(text[0]*3)\n",
    "\n",
    "r.flesch_kincaid().score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
